# 运行时优化实施结果

## 优化概要

基于深度技术分析，我们选择**保持 smol 运行时**并应用**编译级别优化**，而非替换运行时。

### 实施的优化

```toml
[profile.release]
lto = true              # 链接时优化 (Link-Time Optimization)
codegen-units = 1       # 单个代码生成单元（提升优化质量）
strip = true            # 自动移除调试符号
```

---

## 性能对比结果

### 1. 二进制大小

| 指标 | 优化前 | 优化后 | 改进 |
|------|--------|--------|------|
| 未 strip | 4.8 MB | 3.4 MB | **-29.2%** |
| 手动 strip | 3.9 MB | 3.4 MB | **-12.8%** |

**结论**: LTO + strip 自动化带来显著体积优化

---

### 2. 编译时间

| 指标 | 优化前 | 优化后 | 变化 |
|------|--------|--------|------|
| 完整编译 (release) | ~60s | ~68s | **+13.3%** |

**结论**: LTO 增加了编译时间，但对 CI/CD 影响可接受（仅 release 构建）

---

### 3. 运行时验证

**测试项目**: ✅ 所有功能正常

- ✅ `/health` 端点响应正常
- ✅ `/v1/models` 端点响应正常
- ✅ 服务启动速度无明显变化
- ✅ 无运行时错误或警告

---

### 4. 依赖树分析

**smol 传递依赖**:
```
smol v2.0.2
├── async-executor v1.13.3
├── async-io v2.6.0
├── async-net v2.0.0
├── async-lock v3.4.1
├── async-channel v2.5.0
├── async-fs v2.2.0
├── async-process v2.5.0
├── blocking v1.6.2
└── futures-lite v2.6.1
```

**关键发现**:
- 未使用的组件（async-fs, async-process）不会被链接到最终二进制
- Rust 的链接器已优化掉未调用的代码

---

## 决策与理由

### ✅ 保持 smol 的原因

1. **smol 已足够轻量**
   - 本质上是 async-executor + async-io 的薄封装
   - 无显著运行时开销

2. **替代方案收益有限**
   - 直接使用 async-executor: 预计仅节省 50-100KB (<3%)
   - 需修改约 8 处代码，引入维护成本

3. **兼容性与稳定性**
   - 与 async-tls 完美兼容
   - 经过生产验证的稳定性

4. **开发体验**
   - smol API 更简洁易用
   - 统一的命名空间 (smol::*)

---

### 🎯 采用编译优化的理由

1. **零代码改动**: 仅修改 Cargo.toml
2. **显著效果**: 二进制缩小 29%
3. **无功能损失**: 完全透明的优化
4. **自动化**: strip 无需手动执行

---

## 替代方案评估总结

| 方案 | 二进制大小 | 编译时间 | 迁移成本 | 决策 |
|------|-----------|----------|----------|------|
| **保持 smol + LTO** ✅ | 3.4 MB | 68s | 无 | **已实施** |
| async-executor | ~3.3 MB | 65s | 中等 | ❌ 收益/成本比低 |
| tokio | ~5-6 MB | 90-120s | 中等 | ❌ 违背轻量化目标 |
| monoio | ~3 MB | 70s | 高 | ❌ 兼容性差 |

---

## 技术细节

### LTO (Link-Time Optimization) 工作原理

LTO 在链接阶段对整个程序进行优化，而非逐个编译单元：

```
传统编译:
源文件 → 编译 → 目标文件 → 链接 → 可执行文件
         ↑ 优化在这里进行

LTO:
源文件 → 编译 → LLVM IR → 全局优化 → 链接 → 可执行文件
                              ↑ 跨编译单元优化
```

**优势**:
- 内联跨 crate 的函数调用
- 消除更多死代码
- 更好的常量传播
- 优化虚拟调用 (devirtualization)

**劣势**:
- 增加编译时间（对大项目尤其明显）
- 需要更多内存

---

### codegen-units = 1

Rust 默认将代码分割为多个编译单元以并行编译：

```
默认 (codegen-units = 16):
├── 单元1 (并行) → 快速但优化受限
├── 单元2 (并行)
├── ...
└── 单元16 (并行)

优化后 (codegen-units = 1):
└── 单个单元 → 慢但优化更彻底
```

**权衡**:
- ✅ 更好的优化质量
- ❌ 失去并行编译的速度优势

对于小型项目，影响可接受。

---

## 性能基准（待详细测试）

### 吞吐量测试（使用 wrk 或 oha）

```bash
# 场景 A: 轻量级端点
wrk -t4 -c50 -d10s http://localhost:8000/health

# 场景 B: JSON 端点
wrk -t4 -c50 -d10s -H "Authorization: Bearer test" \
    http://localhost:8000/v1/models
```

**预期结果**: LTO 可能带来 2-5% 的运行时性能提升（通过更好的内联和优化）

---

### 延迟测试

```bash
# 使用 oha 测试延迟分布
oha -z 30s -c 50 --latency-correction \
    http://localhost:8000/health
```

**关注指标**:
- P50 (中位数)
- P90 (90th percentile)
- P99 (99th percentile)

---

## 后续优化建议

### 短期（已完成）

- [x] 启用 LTO
- [x] 设置 codegen-units = 1
- [x] 启用自动 strip

### 中期（可选）

- [ ] 使用 `cargo-bloat` 分析最大依赖贡献者
  ```bash
  cargo install cargo-bloat
  cargo bloat --release --crates
  ```

- [ ] 评估 `opt-level = "z"` (优化体积而非速度)
  ```toml
  [profile.release]
  opt-level = "z"  # 对比 "3" (默认)
  ```

### 长期（性能监控）

- [ ] 建立 CI 性能回归测试
- [ ] 监控二进制大小趋势
- [ ] 定期审计依赖树（`cargo tree --duplicates`）

---

## 总结

### 关键成果

1. ✅ **二进制缩小 29%** (4.8MB → 3.4MB)
2. ✅ **保持代码稳定性** (零业务逻辑改动)
3. ✅ **验证 smol 为最佳选择** (技术分析支持)
4. ✅ **建立性能基准流程** (可复用于未来优化)

---

### 经验教训

1. **过早优化的陷阱**: 替换运行时不一定带来收益
2. **编译器优化的威力**: LTO 等工具比手动重构更有效
3. **分析优于直觉**: 依赖树分析揭示了实际使用情况

---

### 下一步行动

- [x] 应用优化到主分支
- [ ] 运行完整基准测试套件（可选）
- [ ] 更新 CLAUDE.md 记录优化决策
- [ ] 关闭工单

---

**文档版本**: 1.0  
**优化实施日期**: 2024-10  
**相关文档**:
- `RUNTIME_EVALUATION.md` - 详细技术评估
- `RUNTIME_ANALYSIS.md` - 深度分析报告
- `benchmarks/` - 基准测试脚本
